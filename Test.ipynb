{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW5oASkm_Xwr",
        "outputId": "ca2ba13e-9db0-488c-e85f-13798b8e1182"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.getcwd() != '/content/drive/My Drive/Pix2Pix':\n",
        "    drive.mount('/content/drive')\n",
        "    %cd drive/MyDrive/Pix2Pix/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Pix2Pix\n",
            "Cyclegan.ipynb   \u001b[0m\u001b[01;34mgenerators\u001b[0m/    \u001b[01;34m__pycache__\u001b[0m/         Tensorboard_Logger.py\n",
            "\u001b[01;34mdata\u001b[0m/            \u001b[01;34mmodels\u001b[0m/        README.md            Test.ipynb\n",
            "\u001b[01;34mdatasets\u001b[0m/        \u001b[01;34mOutputs\u001b[0m/       \u001b[01;34mruns\u001b[0m/                util.py\n",
            "\u001b[01;34mdiscriminators\u001b[0m/  Pix2Pix.ipynb  saved_models.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66FV1FI0-wmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd92e031-18ca-49a7-e99a-882ceebb9b05"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)\n",
        "import argparse\n",
        "import os\n",
        "from math import log10\n",
        "import json\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "from statistics import mean\n",
        "  \n",
        "\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import itertools\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import time\n",
        "from generators.generators import create_gen\n",
        "from discriminators.discriminators import create_disc\n",
        "from datasets.datasets import get_dataset\n",
        "from util import ImagePool, set_requires_grad,tensor_to_plt,init_weights, mkdir\n",
        "from Tensorboard_Logger import Logger"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W30FH3Lp-wmR"
      },
      "source": [
        "class Opt:\n",
        "     def __init__(self, dictionary):\n",
        "        for k, v in dictionary.items():\n",
        "             setattr(self, k, v)\n",
        "\n",
        "def load_opt(folder_name):\n",
        "    path = os.path.join(os.getcwd(),\"models\",folder_name,\"params.txt\")\n",
        "    with open(path) as json_file:\n",
        "        opt = json.load(json_file)\n",
        "    \n",
        "    opt = Opt(opt)\n",
        "    return opt\n",
        "\n",
        "def load_model(folder_name,model_name, opt,device):\n",
        "    G = create_gen(opt.gen,opt.input_dim,opt.output_dim,opt.gen_filters,opt.norm,multigpu=False)\n",
        "    G.to(device)\n",
        "    \n",
        "    checkpoint = torch.load(os.path.join(os.getcwd(),\"models\",folder_name,model_name))\n",
        "    G.load_state_dict(checkpoint[\"gen\"], strict=False) #for cyclegan replace 'gen' with 'genAB'\n",
        "    return G\n",
        "\n",
        "def load_data(photo_path,sketch_path,opt):\n",
        "    data = get_dataset(photo_path,sketch_path, opt,flip=False,jitter=False,erase= False,colored_s=True)\n",
        "    dataset = DataLoader(dataset=data, batch_size=1, shuffle=False,num_workers=4)\n",
        "    return dataset\n",
        "\n",
        "def unnormalize(a):\n",
        "    return a/2 +0.5\n",
        "def onechannel_to_three(a):\n",
        "    return torch.cat((a,a,a),0)\n",
        "def concat_images(photo,sketch,output):\n",
        "    return torch.cat((photo,sketch,output),2)\n",
        "\n",
        "def save_images(dataset,path, colored=False):\n",
        "    for i, batch in enumerate(dataset):\n",
        "        real_A, real_B = batch[0], batch[1]\n",
        "        with torch.no_grad():\n",
        "            out = Gen(real_A.to(device))[0].cpu()\n",
        "            \n",
        "        \n",
        "\n",
        "        a = real_A[0]\n",
        "        a = unnormalize(a)\n",
        "\n",
        "        b = real_B[0]\n",
        "        b = unnormalize(b)\n",
        "        \n",
        "        if not colored:\n",
        "            out = onechannel_to_three(out)\n",
        "            b = onechannel_to_three(b)\n",
        "        \n",
        "        file_name = str(i) +\".jpg\"\n",
        "        save_image(concat_images(a,b,out),os.path.join(path,file_name))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnDoTSos-wmU"
      },
      "source": [
        "folder= \"wgan_tactile_unet_0.5\"\n",
        "opt = load_opt(folder)\n",
        "device = torch.device(\"cuda:0\")\n",
        "Gen = load_model(folder,opt.gen,opt,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-GjlbGc-wmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b56325f-e27e-4816-a04b-7d518567cc11"
      },
      "source": [
        "photo_path_train = os.path.join(os.getcwd(),\"data\",\"tactile\",\"test\", \"photo\")\n",
        "sketch_path_train = os.path.join(os.getcwd(),\"data\",\"tactile\",\"test\", \"sketch\")\n",
        "opt.dataset_name = \"tactile\"\n",
        "dataset = load_data(photo_path_train,sketch_path_train,opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5HI0HxR-wmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c733cb-3e14-4a10-a93c-dd547b971b09"
      },
      "source": [
        "path = os.path.join(os.getcwd(),\"Outputs\",\"wgan_tactile_unet\")\n",
        "mkdir(path)\n",
        "colored = True\n",
        "save_images(dataset,path, colored)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uET7HLSisYhL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e8o87wAa9k7vuImUR349IdVPhww3q6Sc
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os

if os.getcwd() != '/content/drive/My Drive/Pix2Pix':
    drive.mount('/content/drive')
#     %cd drive/MyDrive/Pix2Pix/
# %ls

import torch
import torch.nn as nn
print(torch.__version__)
import argparse
import os
from math import log10
import json

import torch.optim as optim
from torch.utils.data import DataLoader
import torch.backends.cudnn as cudnn

import torchvision
import torchvision.transforms as transforms
from torchvision.utils import save_image


from statistics import mean
  

from torch.nn import init
import functools
import itertools

from torch.autograd import Variable
from torch.optim import lr_scheduler
import numpy as np
import time
from generators.generators import create_gen
from discriminators.discriminators import create_disc
from datasets.datasets import get_dataset
from util import ImagePool, set_requires_grad,tensor_to_plt,init_weights, mkdir
from Tensorboard_Logger import Logger

class Opt:
     def __init__(self, dictionary):
        for k, v in dictionary.items():
             setattr(self, k, v)

def load_opt(folder_name):
    path = os.path.join(os.getcwd(),"models",folder_name,"params.txt")
    with open(path) as json_file:
        opt = json.load(json_file)
    
    opt = Opt(opt)
    return opt

def load_model(folder_name,model_name, opt,device):
    G = create_gen(opt.gen,opt.input_dim,opt.output_dim,opt.gen_filters,opt.norm,multigpu=False)
    G.to(device)
    
    checkpoint = torch.load(os.path.join(os.getcwd(),"models",folder_name,model_name))
    G.load_state_dict(checkpoint["gen"], strict=False) #for cyclegan replace 'gen' with 'genAB'
    return G

def load_data(photo_path,sketch_path,opt):
    data = get_dataset(photo_path,sketch_path, opt,flip=False,jitter=False,erase= False,colored_s=True)
    dataset = DataLoader(dataset=data, batch_size=1, shuffle=False,num_workers=4)
    return dataset

def unnormalize(a):
    return a/2 +0.5
def onechannel_to_three(a):
    return torch.cat((a,a,a),0)
def concat_images(photo,sketch,output):
    return torch.cat((photo,sketch,output),2)

def save_images(dataset,path, colored=False):
    for i, batch in enumerate(dataset):
        real_A, real_B = batch[0], batch[1]
        with torch.no_grad():
            out = Gen(real_A.to(device))[0].cpu()
            
        

        a = real_A[0]
        a = unnormalize(a)

        b = real_B[0]
        b = unnormalize(b)
        
        if not colored:
            out = onechannel_to_three(out)
            b = onechannel_to_three(b)
        
        file_name = str(i) +".jpg"
        save_image(concat_images(a,b,out),os.path.join(path,file_name))

folder= "wgan_tactile_unet_0.5"
opt = load_opt(folder)
device = torch.device("cuda:0")
Gen = load_model(folder,opt.gen,opt,device)

photo_path_train = os.path.join(os.getcwd(),"data","tactile","test", "photo")
sketch_path_train = os.path.join(os.getcwd(),"data","tactile","test", "sketch")
opt.dataset_name = "tactile"
dataset = load_data(photo_path_train,sketch_path_train,opt)

path = os.path.join(os.getcwd(),"Outputs","wgan_tactile_unet")
mkdir(path)
colored = True
save_images(dataset,path, colored)

